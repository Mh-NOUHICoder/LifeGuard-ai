<p align="center">
  <img src="./public/assets/logo.png" alt="LifeGuard AI Logo" width="200"/>
</p>

<h1 align="center">ğŸš¨ LifeGuard AI ğŸš¨</h1>
<p align="center">
  Real-time emergency response powered by <strong>Google Gemini AI</strong><br/>
  Turn your smartphone into a life-saving assistant
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Status-Active-brightgreen?style=for-the-badge" alt="status"/>
  <img src="https://img.shields.io/badge/License-MIT-blue?style=for-the-badge" alt="license"/>
  <img src="https://img.shields.io/badge/Node.js-v18+-green?style=for-the-badge" alt="node"/>
  <img src="https://img.shields.io/badge/Version-1.0.0-blueviolet?style=for-the-badge" alt="version"/>
</p>


---
## ğŸ¬ Demo

<p align="center">
  <img src="./public/assets/demo.gif" alt="LifeGuard AI Demo" width="600"/>
</p>

---

## ğŸ¯ Features

- **Real-time Analysis**: Instant emergency detection using Gemini's multimodal AI  
- **Multilingual Support**: Arabic, French, and English  
- **Voice Guidance**: Text-to-speech instructions in your language  
- **Mobile Optimized**: Works on phones and tablets  
- **Fast & Reliable**: Optimized for low-latency responses in critical moments  
- **Smart Retry**: Automatic retry mechanism for robust analysis  

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+  
- Gemini API Key (get from [Google AI Studio](https://aistudio.google.com))  

### Installation

1. **Clone & Install**
```bash
git clone https://github.com/Mh-NOUHICoder/lifeguard-ai
cd lifeguard-ai
npm install
````

2. **Configure Environment**

```bash
# Create .env.local
echo "API_KEY=your_gemini_api_key_here" > .env.local
```

3. **Run Development Server**

```bash
npm run dev
```

4. **Open in Browser**

```
http://localhost:3000
```

---

## ğŸ—ï¸ Project Structure

```
lifeguard-ai/
â”œâ”€â”€ app/                        # The "Brain" of the Application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ analyze/route.ts    # Core AI analysis engine
â”‚   â”‚   â””â”€â”€ test-gemini/        # Dev testing for AI
â”‚   â”œâ”€â”€ emergency/page.tsx      # Specialized emergency interface
â”‚   â”œâ”€â”€ globals.css             # Global styling and colors
â”‚   â”œâ”€â”€ layout.tsx              # Main wrapper for the app
â”‚   â””â”€â”€ page.tsx                # Landing page & entry point
â”œâ”€â”€ components/                 # The "Body" (UI Elements)
â”‚   â”œâ”€â”€ CameraCapture.tsx       # Live camera & audio
â”‚   â”œâ”€â”€ DangerAlert.tsx         # High-risk visual alerts
â”‚   â”œâ”€â”€ EmergencyButton.tsx     # Push for help button
â”‚   â”œâ”€â”€ LanguageSelector.tsx    # Multilingual toggle
â”‚   â””â”€â”€ DebugPanel.tsx          # Developer AI monitoring
â”œâ”€â”€ lib/                        # The "Nervous System" (Core Logic)
â”‚   â”œâ”€â”€ gemini.ts               # Bridge to Google Gemini AI
â”‚   â”œâ”€â”€ prompt.ts               # AI reasoning logic
â”‚   â”œâ”€â”€ tts.ts                  # Text-to-Speech engine
â”‚   â”œâ”€â”€ translations.ts         # Multi-language dictionary
â”‚   â””â”€â”€ permissions.ts          # Camera/microphone access
â”œâ”€â”€ public/                     # The "Visuals"
â”‚   â”œâ”€â”€ assets/                 # Logos and graphics
â”‚   â”œâ”€â”€ icons/                  # Mobile app icons
â”‚   â”œâ”€â”€ manifest.json           # Makes app installable (PWA)
â”‚   â””â”€â”€ sw.js                   # Service worker
â”œâ”€â”€ types/                      # Code "Definitions"
â”‚   â””â”€â”€ gemini.ts               # AI response types
â””â”€â”€ README.md                   # Full documentation
```

---

## ğŸ“‹ Emergency Types Detected

| Type                | Trigger                                 | Response                                   |
| ------------------- | --------------------------------------- | ------------------------------------------ |
| **Severe Bleeding** | Heavy bleeding, deep wounds, blood loss | Direct pressure, elevation, emergency call |
| **Fire/Smoke**      | Flames, fire, smoke                     | Evacuate, stop-drop-roll, call emergency   |
| **Not Emergency**   | Normal scene                            | No action needed                           |

---

## ğŸ“± UX Flow

1. Select Language (AR / FR / EN)
2. Press Emergency Button (large red)
3. Allow Camera & Microphone access
4. Tap "ANALYZE SCENE" to capture image & audio
5. Receive instructions (displayed & spoken)
6. Optional: Call emergency services

---

## ğŸ”Š Text-to-Speech

Supports natural speech in:

* **Arabic (ar-SA)** â€“ Right-to-left
* **French (fr-FR)**
* **English (en-US)**

```typescript
import { speak, stopSpeech } from '@/lib/tts';

await speak("Emergency instruction", Language.ARABIC, {
  rate: 1.2,
  pitch: 1,
  volume: 1
});

stopSpeech();
```

---

## ğŸš€ Deployment

### Vercel (Recommended)

```bash
vercel deploy
```

### Docker

```bash
docker build -t lifeguard-ai .
docker run -p 3000:3000 lifeguard-ai
```

---

## ğŸ”’ Security

* API key in `.env.local` (never committed)
* No data logging of emergency scenes
* Client-side camera/audio processing only
* HTTPS required

---

## ğŸ¤ Contributing

1. Test edge cases
2. Report bugs with screenshots
3. Suggest UX improvements
4. Add more language support

---

## ğŸ“„ License

MIT License â€“ Safe for personal & commercial use

---

## ğŸ†˜ Support

* Issues? Check browser console
* No camera? Grant browser permissions
* API errors? Verify Gemini API key

---

**Save lives. Every second counts. ğŸš¨**

```

